{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laundry Symbol Recognition using Convolutional Neural Networks\n",
    "\n",
    "## Welcome\n",
    "In this hands-on session we will guide you through the following content:\n",
    "- Image data visualization\n",
    "- Image data augmentation\n",
    "- Training your own CNN based model for image recognition\n",
    "- Optimizing the performance of your model\n",
    "- Applying the trained model to classify images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data visualization\n",
    "Before you start to train your deep learning models, it is always a good practice to get some intuition about your data at first.\n",
    "\n",
    "But before that, let's import some libraries that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob \n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.03\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell will display the first image sample from each class in our training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 3\n",
    "for i in range(1, len(next(os.walk('data/train'))[1])+1): \n",
    "    folder_name = next(os.walk('data/train'))[1][i-1]\n",
    "    img = Image.open(glob.glob('data/train/' + folder_name + '/*.tif')[0], 'r')\n",
    "    fig.add_subplot(rows, columns, i, title=folder_name)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most practical deep learning applications, overfitting is one of the most common issues which need to be overcome.\n",
    "\n",
    ">In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\". \n",
    "\n",
    "--- Wikipedia\n",
    "\n",
    "A very common yet effective technique to avoid overfitting is to use data augmentation.\n",
    "\n",
    "By using ImageDataGenerator class from keras, image data can be augmented on the fly. Let's import it first:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the following code cell, we will load and display a single image from our training set. This will be the 'seed image' for the coming data augmentation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('data/train/1_waschen30_1_96/Bilderkennung_00003_Waschen_96.tif')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (96, 96, 3)\n",
    "fig=plt.figure(figsize=(3, 3))\n",
    "fig.add_subplot(111, title='Original')\n",
    "plt.imshow(x/255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save images generated by the ImageDataGenerator, we need to create a new folder called \"augmented_images\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('augmented_images')\n",
    "except FileExistsError:\n",
    "    # if directory already exists\n",
    "    shutil.rmtree('augmented_images')\n",
    "    os.mkdir('augmented_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the augmentation needed in the following cell (feel free to modify the parameters and re-run the next 3 cells to see the effects): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataGenerator.flow() method takes 4-D \"batched\" image data with form (batch_size, img_height, img_width, #channels) as input, so the original 3-D images array must be \"extended\" with one additional dimention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = x.reshape((1,) + x.shape) # this now a Numpy array with shape (1, img_height, img_width, #channels)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `augmented_images` directory\n",
    "i = 0\n",
    "for batch in augmentation_datagen.flow(x_reshaped, batch_size=1,\n",
    "                          save_to_dir='augmented_images', save_prefix='augmented_', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 8:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the augmented images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('Augmented Images')\n",
    "columns = 3\n",
    "rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = Image.open(glob.glob('augmented_images' + '/*.jpg')[i-1], 'r')\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your own CNN based model for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally start training our CNN model! To do so, again we need to import the necessary libraries first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although one great thing about machine learning is that the model parameters can be \"automatically\" learned during training, we still need to configure some parameters manually. Typically, these parameters include data batch size, number of network layers and number of neurons in each layer... \n",
    "\n",
    "We call this kind of parameters \"hyperparameters\".\n",
    "\n",
    "In our case, the input image size and batch size belong to them. So, let's define them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 96, 96\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the training data as well as the validation data for our training, we'll use the following two ImageDataGenerators, respectively. \n",
    "\n",
    "To be noticed, we'll convert the images into grayscale images for computing efficiency reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/val'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "#        shear_range=0.1, \n",
    "#        zoom_range=0.1,\n",
    "#        rotation_range=10,\n",
    "        )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    seed=8\n",
    "    )\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    seed=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build our neural network model. \n",
    "\n",
    "With keras, it can be pretty much like building legos: you just stack the parts you want, layer by layer (here I just write the code a little bit explicitly on purpose, to make it more self-explainary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=[img_height, img_width, 1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "          \n",
    "model.add(Dense(train_generator.num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the model, you also need to configure it with the method \"compile\". Typically, here you want to choose the loss function, optimizer and the metrics for training the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another hyperparameter we want to define is the number of training epochs. One epoch is one training iteration over the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = train_generator.n # number of training samples\n",
    "nb_validation_samples = validation_generator.n # number of validation samples\n",
    "nb_epochs = 10 # number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll begin training our model on data generated batch-by-batch using ImageDataGenerator. After finishing every training epoch, one validation on our validation set will be triggered as well. \n",
    "\n",
    "You can observe the metric values during the training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size + 1,\n",
    "        epochs=nb_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size + 1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have noticed, the validation loss somehow didn't decrease anymore during the last few epochs, it indicates that the model has been fitted to the data. Otherwise you should enlarge the number of training epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model has been trained, now it's time for us to test it's final (generalization) performance. To do so, we need to use our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'data/test'\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode=None) # no labels for predict_generator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need to import some evaluation tools to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now start the model evaluation by:\n",
    "1. letting it make class predictions on all test samples\n",
    "2. comparing the predictions with ground truth we can get several metrics indicating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(test_generator, test_generator.n // batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1) # indice of class with the highest confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_correct = np.sum(test_generator.classes==y_pred)\n",
    "print('Test Accuracy: {}%'.format(nb_pred_correct/test_generator.n*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voluntary task: Are you satisfied with this result? If not, how can you improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_single_img(model, img, label_dict):\n",
    "    x = img_to_array(img)/255. # rescale\n",
    "    x = np.expand_dims(x, axis=0) # extend dimesion\n",
    "    y_pred = model.predict(x) \n",
    "    class_pred = y_pred[0].argmax(axis=-1) \n",
    "    return label_dict[class_pred], max(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are now satisfied with your model performance, you can proceed with the remaining part:\n",
    "\n",
    "To verify and get some feeling about the model you have just trained, we would like to output some the predictions of our test samples as well as compare them of the ground truth:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output the predictions in a human-readable form, we need a dictionary to map the model output to label text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {y:x for x,y in test_generator.class_indices.items()} # {class number : text label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the code cell below to see the result and convince yourself of the discriminative power of CNN:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 20))\n",
    "columns = 2\n",
    "rows = 5\n",
    "for i in range(1, len(next(os.walk('data/test'))[1])+1): \n",
    "    folder_name = next(os.walk('data/test'))[1][i-1]\n",
    "    img = glob.glob('data/test/' + folder_name + '/*.tif')[0]\n",
    "    img = load_img(img, target_size=(img_height, img_width), color_mode='grayscale')\n",
    "    pred, confidence = predict_on_single_img(model, img, label_dict)\n",
    "    fig.add_subplot(rows, columns, i, \n",
    "                    title='True: {} / Pred.: {} / Conf.: {:.4f}'.format(folder_name, pred, confidence))\n",
    "    plt.imshow(img, cmap='gray')      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this hands-on training, you have learned:\n",
    "\n",
    "- How to build a image dataset\n",
    "- How to augment image data to avoid overfitting\n",
    "- How to train a convolutional neural network from scratch\n",
    "- How to evaluate the trained model\n",
    "- ### And, most importantly, experience the power and fun of deep learning by yourself:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you are eager to learn even more about the topic...\n",
    "* [Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721) - A more in-detailed introduction to convolutional neural networks.\n",
    "* [Deep Learning with Python](https://www.amazon.de/Deep-Learning-with-Python/dp/B07H5TKXHN/ref=sr_1_6?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=26ZPNVY500LY2&keywords=deep+learning+with+python&qid=1560441999&s=books-intl-de&sprefix=deep+learning+with+p%2Caps%2C291&sr=1-6) - Very good book with intuitive explanations and practical examples! By the creator of keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
